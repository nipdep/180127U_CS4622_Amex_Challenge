{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook we build and train an XGBoost model using @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. This XGB model achieves CV 0.792 LB 0.793! When training with XGB, we use a special XGB dataloader called `DeviceQuantileDMatrix` which uses a small GPU memory footprint. This allows us to engineer more additional columns and train with more rows of data. Our feature engineering is performed using [RAPIDS][5] on the GPU to create new features quickly.\n\n[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n[5]: https://rapids.ai/","metadata":{}},{"cell_type":"markdown","source":"# Load Libraries","metadata":{}},{"cell_type":"code","source":"# LOAD LIBRARIES\nimport pandas as pd, numpy as np # CPU libraries\nimport json \nimport cupy, cudf # GPU libraries\nimport matplotlib.pyplot as plt, gc, os\n\nprint('RAPIDS version', cudf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:27.392981Z","iopub.execute_input":"2022-12-20T13:45:27.393428Z","iopub.status.idle":"2022-12-20T13:45:28.321555Z","shell.execute_reply.started":"2022-12-20T13:45:27.393341Z","shell.execute_reply":"2022-12-20T13:45:28.320533Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"RAPIDS version 21.10.01\n","output_type":"stream"}]},{"cell_type":"code","source":"# VERSION NAME FOR SAVED MODEL FILES\nVER = 1\n\n# TRAIN RANDOM SEED\nSEED = 42\n\n# FILL NAN VALUE\nNAN_VALUE = -127  # will fit in int8\n\n# FOLDS PER MODEL\nFOLDS = 5","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:28.323883Z","iopub.execute_input":"2022-12-20T13:45:28.324327Z","iopub.status.idle":"2022-12-20T13:45:28.331019Z","shell.execute_reply.started":"2022-12-20T13:45:28.324288Z","shell.execute_reply":"2022-12-20T13:45:28.328575Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Process and Feature Engineer Train Data\nWe will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n\n[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n[5]: https://rapids.ai/","metadata":{}},{"cell_type":"code","source":"with open('../input/amex-cols/col_dict (1).json', 'r') as pf:\n    col_dict = json.load(pf)\n\ncol_dict.keys()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:40.032304Z","iopub.execute_input":"2022-12-20T13:45:40.032776Z","iopub.status.idle":"2022-12-20T13:45:40.045393Z","shell.execute_reply.started":"2022-12-20T13:45:40.032741Z","shell.execute_reply":"2022-12-20T13:45:40.044128Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"dict_keys(['drop -1', 'drop nan', 'drop 0', 'drop object', 'cats', 'usable'])"},"metadata":{}}]},{"cell_type":"code","source":"skip_cols = list(set(col_dict['drop -1'])|set(col_dict['drop nan'])|set(col_dict['drop 0']))\nuse_cols = ['customer_ID', 'S_2']+col_dict['usable']","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:44.432283Z","iopub.execute_input":"2022-12-20T13:45:44.432661Z","iopub.status.idle":"2022-12-20T13:45:44.438426Z","shell.execute_reply.started":"2022-12-20T13:45:44.432628Z","shell.execute_reply":"2022-12-20T13:45:44.437005Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def read_file(path = '', usecols = None):\n    # LOAD DATAFRAME\n    if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n    else: df = cudf.read_parquet(path)\n    # REDUCE DTYPE FOR CUSTOMER AND DATE\n    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n\n    df.S_2 = cudf.to_datetime( df.S_2 )\n    df['S_20'] = df.S_2.dt.month\n    df['S_21'] = df.S_2.dt.dayofweek\n    \n    # SORT BY CUSTOMER AND DATE (so agg('last') works correctly)\n    df = df.sort_values(['customer_ID','S_2'])\n    #df = df.reset_index(drop=True)\n    df.drop(columns=['S_2'], inplace=True)\n    # FILL NAN\n    df = df.fillna(NAN_VALUE) \n    print('shape of data:', df.shape)\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:44.731634Z","iopub.execute_input":"2022-12-20T13:45:44.732090Z","iopub.status.idle":"2022-12-20T13:45:44.740298Z","shell.execute_reply.started":"2022-12-20T13:45:44.732051Z","shell.execute_reply":"2022-12-20T13:45:44.739319Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print('Reading train data...')\nTRAIN_PATH = '../input/amex-data-integer-dtypes-parquet-format/train.parquet'\ntrain = read_file(path = TRAIN_PATH, usecols=use_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_and_feature_engineer(df):\n    # FEATURE ENGINEERING FROM \n    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_68\"]\n    num_features = [col for col in all_cols if col not in cat_features]\n\n    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n\n    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n    \n    # get temporal value difference & group ops.\n    \n#     sub_df = cudf.DataFrame()  \n#     sub_df['customer_ID'] = df[\"customer_ID\"]\n#     for ft in num_features:\n#         sub_df[ft] = df[ft].diff().fillna(0)\n#     diff_num_agg = sub_df.groupby('customer_ID')[num_features].agg([\"mean\", 'std', 'min', 'max', 'last'])\n\n    df = cudf.concat([test_num_agg, test_cat_agg], axis=1)\n    del test_num_agg, test_cat_agg\n    print('shape after engineering', df.shape )\n    \n    return df\n\n# train = process_and_feature_engineer(train)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:46.821862Z","iopub.execute_input":"2022-12-20T13:45:46.822497Z","iopub.status.idle":"2022-12-20T13:45:46.835505Z","shell.execute_reply.started":"2022-12-20T13:45:46.822450Z","shell.execute_reply":"2022-12-20T13:45:46.834461Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = process_and_feature_engineer(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ADD TARGETS\ntargets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\ntargets = targets.set_index('customer_ID')\ntrain = train.merge(targets, left_index=True, right_index=True, how='left')\ntrain.target = train.target.astype('int8')\ndel targets\n# train['customer_ID'] = train['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n\n# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\ntrain = train.sort_index().reset_index()\n\n# FEATURES\nFEATURES = train.columns[1:-1]\nprint(f'There are {len(FEATURES)} features!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"./FEATURES.json\", 'w') as pf:\n    json.dump({\"FEATURES\": list(FEATURES)}, pf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train XGB\nWe will train using `DeviceQuantileDMatrix`. This has a very small GPU memory footprint.","metadata":{}},{"cell_type":"code","source":"# LOAD XGB LIBRARY\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nprint('XGB Version',xgb.__version__)\n\n# XGB MODEL PARAMETERS\nxgb_parms = { \n    'max_depth':5, \n    'learning_rate':0.05, \n    'subsample':0.8,\n    'colsample_bytree':0.6, \n    'eval_metric':'logloss',\n    'objective':'binary:logistic',\n    'tree_method':'gpu_hist',\n    'predictor':'gpu_predictor',\n    'random_state':SEED\n}","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:53.473676Z","iopub.execute_input":"2022-12-20T13:45:53.474175Z","iopub.status.idle":"2022-12-20T13:45:54.040071Z","shell.execute_reply.started":"2022-12-20T13:45:53.474129Z","shell.execute_reply":"2022-12-20T13:45:54.039018Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"XGB Version 1.6.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# NEEDED WITH DeviceQuantileDMatrix BELOW\nclass IterLoadForDMatrix(xgb.core.DataIter):\n    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n        self.features = features\n        self.target = target\n        self.df = df\n        self.it = 0 # set iterator to 0\n        self.batch_size = batch_size\n        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n        super().__init__()\n\n    def reset(self):\n        '''Reset the iterator'''\n        self.it = 0\n\n    def next(self, input_data):\n        '''Yield next batch of data.'''\n        if self.it == self.batches:\n            return 0 # Return 0 when there's no more batch.\n        \n        a = self.it * self.batch_size\n        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n        dt = cudf.DataFrame(self.df.iloc[a:b])\n        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n        self.it += 1\n        return 1","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:54.042006Z","iopub.execute_input":"2022-12-20T13:45:54.042637Z","iopub.status.idle":"2022-12-20T13:45:54.053610Z","shell.execute_reply.started":"2022-12-20T13:45:54.042598Z","shell.execute_reply":"2022-12-20T13:45:54.052593Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/kyakovlev\n# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n\ndef amex_metric_mod(y_true, y_pred):\n\n    labels     = np.transpose(np.array([y_true, y_pred]))\n    labels     = labels[labels[:, 1].argsort()[::-1]]\n    weights    = np.where(labels[:,0]==0, 20, 1)\n    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n\n    gini = [0,0]\n    for i in [1,0]:\n        labels         = np.transpose(np.array([y_true, y_pred]))\n        labels         = labels[labels[:, i].argsort()[::-1]]\n        weight         = np.where(labels[:,0]==0, 20, 1)\n        weight_random  = np.cumsum(weight / np.sum(weight))\n        total_pos      = np.sum(labels[:, 0] *  weight)\n        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n        lorentz        = cum_pos_found / total_pos\n        gini[i]        = np.sum((lorentz - weight_random) * weight)\n\n    return 0.5 * (gini[1]/gini[0] + top_four)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:45:54.692164Z","iopub.execute_input":"2022-12-20T13:45:54.692529Z","iopub.status.idle":"2022-12-20T13:45:54.709270Z","shell.execute_reply.started":"2022-12-20T13:45:54.692498Z","shell.execute_reply":"2022-12-20T13:45:54.703732Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"importances = []\noof = []\ntrain = train.to_pandas() # free GPU memory\nTRAIN_SUBSAMPLE = 1.0\ngc.collect()\n\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    \n    # TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\n    if TRAIN_SUBSAMPLE<1.0:\n        np.random.seed(SEED)\n        train_idx = np.random.choice(train_idx, \n                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n        np.random.seed(None)\n    \n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    \n    # TRAIN, VALID, TEST FOR FOLD K\n    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n    X_valid = train.loc[valid_idx, FEATURES]\n    y_valid = train.loc[valid_idx, 'target']\n    \n    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n    \n    # TRAIN MODEL FOLD K\n    model = xgb.train(xgb_parms, \n                dtrain=dtrain,\n                evals=[(dtrain,'train'),(dvalid,'valid')],\n                num_boost_round=9999,\n                early_stopping_rounds=100,\n                verbose_eval=100) \n    model.save_model(f'XGB_v{VER}_fold{fold}.xgb')\n    \n    # GET FEATURE IMPORTANCE FOR FOLD K\n    dd = model.get_score(importance_type='weight')\n    df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n    importances.append(df)\n            \n    # INFER OOF FOLD K\n    oof_preds = model.predict(dvalid)\n    acc = amex_metric_mod(y_valid.values, oof_preds)\n    print('Kaggle Metric =',acc,'\\n')\n    \n    # SAVE OOF\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = oof_preds\n    oof.append( df )\n    \n    del dtrain, Xy_train, dd, df\n    del X_valid, y_valid, dvalid, model\n    _ = gc.collect()\n    \nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\nprint('OVERALL CV Kaggle Metric =',acc)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-20T13:45:55.362260Z","iopub.execute_input":"2022-12-20T13:45:55.362627Z","iopub.status.idle":"2022-12-20T13:45:55.522024Z","shell.execute_reply.started":"2022-12-20T13:45:55.362596Z","shell.execute_reply":"2022-12-20T13:45:55.520475Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1415/306355850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# free GPU memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mTRAIN_SUBSAMPLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"],"ename":"NameError","evalue":"name 'train' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# CLEAN RAM\ndel train\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save OOF Preds","metadata":{}},{"cell_type":"code","source":"oof_xgb = pd.read_parquet(TRAIN_PATH, columns=['customer_ID']).drop_duplicates()\noof_xgb['customer_ID_hash'] = oof_xgb['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\noof_xgb = oof_xgb.set_index('customer_ID_hash')\noof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\noof_xgb = oof_xgb.sort_index().reset_index(drop=True)\noof_xgb.to_csv(f'oof_xgb_v{VER}.csv',index=False)\noof_xgb.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOT OOF PREDICTIONS\nplt.hist(oof_xgb.oof_pred.values, bins=100)\nplt.title('OOF Predictions')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CLEAR VRAM, RAM FOR INFERENCE BELOW\ndel oof_xgb, oof\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf = importances[0].copy()\nfor k in range(1,FOLDS): df = df.merge(importances[k], on='feature', how='left')\ndf['importance'] = df.iloc[:,1:].mean(axis=1)\ndf = df.sort_values('importance',ascending=False)\ndf.to_csv(f'xgb_feature_importance_v{VER}.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_FEATURES = 20\nplt.figure(figsize=(10,5*NUM_FEATURES//10))\nplt.barh(np.arange(NUM_FEATURES,0,-1), df.importance.values[:NUM_FEATURES])\nplt.yticks(np.arange(NUM_FEATURES,0,-1), df.feature.values[:NUM_FEATURES])\nplt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process and Feature Engineer Test Data\nWe will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][1] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n\n[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n[5]: https://rapids.ai/","metadata":{}},{"cell_type":"code","source":"# CALCULATE SIZE OF EACH SEPARATE TEST PART\ndef get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n    chunk = len(customers)//NUM_PARTS\n    if verbose != '':\n        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n        print(f'There will be {chunk} customers in each part (except the last part).')\n        print('Below are number of rows in each part:')\n    rows = []\n\n    for k in range(NUM_PARTS):\n        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n        else: cc = customers[k*chunk:(k+1)*chunk]\n        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n        rows.append(s)\n    if verbose != '': print( rows )\n    return rows,chunk\n\n# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\nNUM_PARTS = 10\nTEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'\n\nprint(f'Reading test data...')\ntest = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n# test['customer_ID'] = test['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n# customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\ncustomers = test['customer_ID'].unique()\n# test = test.sort_values(by=['customer_ID'])\nrows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:46:06.543279Z","iopub.execute_input":"2022-12-20T13:46:06.544014Z","iopub.status.idle":"2022-12-20T13:46:09.935501Z","shell.execute_reply.started":"2022-12-20T13:46:06.543973Z","shell.execute_reply":"2022-12-20T13:46:09.934252Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Reading test data...\nshape of data: (11363762, 3)\nWe will process test data as 10 separate parts.\nThere will be 92462 customers in each part (except the last part).\nBelow are number of rows in each part:\n[1136059, 1135980, 1136098, 1136825, 1136206, 1136299, 1137604, 1136586, 1135635, 1136470]\n","output_type":"stream"}]},{"cell_type":"code","source":"customers.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:46:15.523516Z","iopub.execute_input":"2022-12-20T13:46:15.524126Z","iopub.status.idle":"2022-12-20T13:46:15.537449Z","shell.execute_reply.started":"2022-12-20T13:46:15.524079Z","shell.execute_reply":"2022-12-20T13:46:15.536530Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(924621,)"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:46:15.871717Z","iopub.execute_input":"2022-12-20T13:46:15.872080Z","iopub.status.idle":"2022-12-20T13:46:15.896188Z","shell.execute_reply.started":"2022-12-20T13:46:15.872049Z","shell.execute_reply":"2022-12-20T13:46:15.895114Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                 customer_ID  S_20  S_21\n5468998 -9223277493928322471     4     0\n5468999 -9223277493928322471     5     3\n5469000 -9223277493928322471     6     4\n5469001 -9223277493928322471     7     1\n5469002 -9223277493928322471     8     4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_ID</th>\n      <th>S_20</th>\n      <th>S_21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5468998</th>\n      <td>-9223277493928322471</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5468999</th>\n      <td>-9223277493928322471</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5469000</th>\n      <td>-9223277493928322471</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5469001</th>\n      <td>-9223277493928322471</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5469002</th>\n      <td>-9223277493928322471</td>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:46:17.612316Z","iopub.execute_input":"2022-12-20T13:46:17.612717Z","iopub.status.idle":"2022-12-20T13:46:17.621095Z","shell.execute_reply.started":"2022-12-20T13:46:17.612682Z","shell.execute_reply":"2022-12-20T13:46:17.620084Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(11363762, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Infer Test","metadata":{}},{"cell_type":"code","source":"with open('./FEATURES.json', 'r') as pf:\n    FEATURES = json.load(pf)['FEATURES']","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:46:19.612072Z","iopub.execute_input":"2022-12-20T13:46:19.612468Z","iopub.status.idle":"2022-12-20T13:46:19.618619Z","shell.execute_reply.started":"2022-12-20T13:46:19.612435Z","shell.execute_reply":"2022-12-20T13:46:19.617336Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# INFER TEST DATA IN PARTS\nskip_rows = 0\nskip_cust = 0\ntest_preds = []\n\nfor k in range(NUM_PARTS):\n    \n    # READ PART OF TEST DATA\n    print(f'\\nReading test data...')\n    test = read_file(path = TEST_PATH)\n#     test['customer_ID'] = test['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n#     test = test.set_index('customer_ID')\n    test = test.iloc[skip_rows:skip_rows+rows[k]]\n    skip_rows += rows[k]\n    print(f'=> Test part {k+1} has shape', test.shape )\n    \n    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n    test = process_and_feature_engineer(test)\n    \n    \n    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n    skip_cust += num_cust\n    \n    # TEST DATA FOR XGB\n    X_test = test[FEATURES]\n    dtest = xgb.DMatrix(data=X_test)\n    del X_test\n    gc.collect()\n\n    # INFER XGB MODELS ON TEST DATA\n    model = xgb.Booster()\n    model.load_model(f'XGB_v{VER}_fold0.xgb')\n    preds = model.predict(dtest)\n    for f in range(1,FOLDS):\n        model.load_model(f'XGB_v{VER}_fold{f}.xgb')\n        preds += model.predict(dtest)\n    preds /= FOLDS\n    test_preds.append(preds)\n\n    # CLEAN MEMORY\n    del dtest, model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:46:20.752097Z","iopub.execute_input":"2022-12-20T13:46:20.752478Z","iopub.status.idle":"2022-12-20T13:48:26.011390Z","shell.execute_reply.started":"2022-12-20T13:46:20.752447Z","shell.execute_reply":"2022-12-20T13:48:26.010083Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 1 has shape (1136059, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 2 has shape (1135980, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 3 has shape (1136098, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 4 has shape (1136825, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 5 has shape (1136206, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 6 has shape (1136299, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 7 has shape (1137604, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 8 has shape (1136586, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 9 has shape (1135635, 190)\nshape after engineering (92462, 927)\n\nReading test data...\nshape of data: (11363762, 190)\n=> Test part 10 has shape (1136470, 190)\nshape after engineering (92463, 927)\n","output_type":"stream"}]},{"cell_type":"code","source":"np.concatenate(test_preds).shape","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:50:03.981283Z","iopub.execute_input":"2022-12-20T13:50:03.981674Z","iopub.status.idle":"2022-12-20T13:50:03.990893Z","shell.execute_reply.started":"2022-12-20T13:50:03.981641Z","shell.execute_reply":"2022-12-20T13:50:03.989882Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(924621,)"},"metadata":{}}]},{"cell_type":"code","source":"customers.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:50:05.662125Z","iopub.execute_input":"2022-12-20T13:50:05.664240Z","iopub.status.idle":"2022-12-20T13:50:05.670842Z","shell.execute_reply.started":"2022-12-20T13:50:05.664198Z","shell.execute_reply":"2022-12-20T13:50:05.669795Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(924621,)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create Submission CSV","metadata":{}},{"cell_type":"code","source":"print(test[['prediction']].shape, sub.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test['customer_ID'].uniques().shape, test_preds1.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WRITE SUBMISSION FILE\ntest_preds1 = np.concatenate(test_preds)\ntest = cudf.DataFrame(index=customers, data={'prediction':test_preds1})\nsub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')[['customer_ID']]\nsub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\nsub = sub.set_index('customer_ID_hash')\nsub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\nsub = sub.reset_index(drop=True)\n\n# DISPLAY PREDICTIONS\nsub.to_csv(f'submission_xgb_v{VER}.csv',index=False)\nprint('Submission file shape is', sub.shape )\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-20T13:51:11.752823Z","iopub.execute_input":"2022-12-20T13:51:11.753303Z","iopub.status.idle":"2022-12-20T13:51:13.144131Z","shell.execute_reply.started":"2022-12-20T13:51:11.753250Z","shell.execute_reply":"2022-12-20T13:51:13.143096Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Submission file shape is (924621, 2)\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                         customer_ID  prediction\n0  0f7f94e1247f12d2a38fb2b014d6be7175f51b3b4efe9b...    0.042473\n1  0f8086f7297593825bba8c654ea9d35f661089ce25ed79...    0.089084\n2  0f7fe57b8ce23fdd299b99cbcf7fac47e0cdf6459bb616...    0.073528\n3  0f81168c4911b484975ff222f75321396c546b700fa329...    0.048500\n4  0f7f94e3f0e63573b61dccc9fb3c4091ccc8d283d7b58a...    0.012819","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_ID</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0f7f94e1247f12d2a38fb2b014d6be7175f51b3b4efe9b...</td>\n      <td>0.042473</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0f8086f7297593825bba8c654ea9d35f661089ce25ed79...</td>\n      <td>0.089084</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0f7fe57b8ce23fdd299b99cbcf7fac47e0cdf6459bb616...</td>\n      <td>0.073528</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0f81168c4911b484975ff222f75321396c546b700fa329...</td>\n      <td>0.048500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0f7f94e3f0e63573b61dccc9fb3c4091ccc8d283d7b58a...</td>\n      <td>0.012819</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# PLOT PREDICTIONS\nplt.hist(sub.to_pandas().prediction, bins=100)\nplt.title('Test Predictions')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}