{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Load Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:06.165908Z","iopub.status.busy":"2022-11-29T05:59:06.165484Z","iopub.status.idle":"2022-11-29T05:59:07.262900Z","shell.execute_reply":"2022-11-29T05:59:07.261617Z","shell.execute_reply.started":"2022-11-29T05:59:06.165826Z"},"trusted":true},"outputs":[],"source":["# LOAD LIBRARIES\n","import pandas as pd, numpy as np # CPU libraries\n","import cupy, cudf # GPU libraries\n","import matplotlib.pyplot as plt, gc, os\n","import json \n","print('RAPIDS version',cudf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:07.265000Z","iopub.status.busy":"2022-11-29T05:59:07.264727Z","iopub.status.idle":"2022-11-29T05:59:07.269707Z","shell.execute_reply":"2022-11-29T05:59:07.268582Z","shell.execute_reply.started":"2022-11-29T05:59:07.264973Z"},"trusted":true},"outputs":[],"source":["# VERSION NAME FOR SAVED MODEL FILES\n","VER = 1\n","\n","# TRAIN RANDOM SEED\n","SEED = 42\n","\n","# FILL NAN VALUE\n","NAN_VALUE = -127 # will fit in int8\n","\n","# FOLDS PER MODEL\n","FOLDS = 5"]},{"cell_type":"markdown","metadata":{},"source":["# Process and Feature Engineer Train Data\n","We will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n","\n","[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n","[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n","[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n","[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n","[5]: https://rapids.ai/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:09.755940Z","iopub.status.busy":"2022-11-29T05:59:09.755561Z","iopub.status.idle":"2022-11-29T05:59:09.762901Z","shell.execute_reply":"2022-11-29T05:59:09.761730Z","shell.execute_reply.started":"2022-11-29T05:59:09.755908Z"},"trusted":true},"outputs":[],"source":["def read_file(path = '', usecols = None):\n","    # LOAD DATAFRAME\n","    if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n","    else: df = cudf.read_parquet(path)\n","    # REDUCE DTYPE FOR CUSTOMER AND DATE\n","    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n","    df.S_2 = cudf.to_datetime( df.S_2 )\n","    # SORT BY CUSTOMER AND DATE (so agg('last') works correctly)\n","    df = df.sort_values(['customer_ID','S_2'])\n","    #df = df.reset_index(drop=True)\n","    # FILL NAN\n","#     df = df.fillna(NAN_VALUE) \n","    print('shape of data:', df.shape)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print('Reading train data...')\n","TRAIN_PATH = '../input/amex-data-integer-dtypes-parquet-format/train.parquet'\n","train = read_file(path = TRAIN_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:13.157797Z","iopub.status.busy":"2022-11-29T05:59:13.157077Z","iopub.status.idle":"2022-11-29T05:59:13.171839Z","shell.execute_reply":"2022-11-29T05:59:13.170844Z","shell.execute_reply.started":"2022-11-29T05:59:13.157761Z"},"trusted":true},"outputs":[],"source":["# drop NAN and missing value filled columns\n","drop_nan_cols = ['D_88', 'D_110', 'B_39', 'D_73', 'B_42', 'D_134', 'B_29', 'D_132', 'D_76', 'D_42', 'D_142', 'D_53']\n","drop_min1_cols = ['D_49', 'D_66', 'R_9', 'D_82', 'D_87', 'D_106', 'R_26', 'D_108', 'D_111', 'D_135', 'D_136', 'D_137', 'D_138']\n","drop_zero_cols = ['R_18', 'R_23', 'R_28', 'D_109', 'R_25', 'R_22', 'R_17', 'R_13', 'D_93', 'S_20', 'R_24', 'R_14', 'D_89', 'R_20', 'R_15', 'R_21', 'D_94', 'R_19', 'R_8', 'B_41', 'B_32', 'R_4', 'R_7', 'S_18', 'R_5', 'D_140', 'D_96', 'D_86', 'D_116', 'D_81', 'R_2', 'D_65', 'D_84', 'R_10', 'D_72', 'D_83', 'D_123', 'R_16', 'R_11', 'D_92']\n","\n","all_drop_cols = list(set(drop_nan_cols)|set(drop_min1_cols)|set(drop_zero_cols))\n","\n","def process_and_feature_engineer(df):\n","    # FEATURE ENGINEERING FROM \n","    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n","    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n","    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n","    \n","    # drop custom NAN cols \n","    all_cols = [i for i in all_cols if i not in all_drop_cols]\n","    cat_features = [i for i in cat_features if i not in all_drop_cols]\n","    \n","    num_features = [col for col in all_cols if col not in cat_features]\n","\n","    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n","    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n","\n","    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n","    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n","    \n","    # add datatime period features\n","#     df['S_2_yr'] = df['S_2'].dt.year\n","#     test_yr_agg = df.groupby(\"customer_ID\")['S_2_yr'].agg(['nunique', 'max'])\n","#     test_yr_agg.columns = ['_'.join(x)+'_yr' for x in test_yr_agg.columns]\n","    \n","    df['S_2_mnth'] = df['S_2'].dt.month\n","    test_mnth_agg = df.groupby(\"customer_ID\")['S_2_mnth'].agg(['count', 'last'])\n","    test_mnth_agg.columns = ['_'.join(x)+'_mnth' for x in test_mnth_agg.columns]\n","\n","    df = cudf.concat([test_num_agg, test_cat_agg, test_mnth_agg], axis=1)\n","    del test_num_agg, test_cat_agg, test_mnth_agg\n","    print('shape after engineering', df.shape )\n","    \n","    return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = process_and_feature_engineer(train)\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# ADD TARGETS\n","targets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\n","targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n","targets = targets.set_index('customer_ID')\n","train = train.merge(targets, left_index=True, right_index=True, how='left')\n","train.target = train.target.astype('int8')\n","del targets\n","\n","# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n","train = train.sort_index().reset_index()\n","\n","# FEATURES\n","FEATURES = train.columns[1:-1]\n","print(f'There are {len(FEATURES)} features!')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with open('/kaggle/working/FEATURES.json', 'w') as pf:\n","    json.dump({\"FEATURES\": list(FEATURES)}, pf)"]},{"cell_type":"markdown","metadata":{},"source":["# Train XGB\n","We will train using `DeviceQuantileDMatrix`. This has a very small GPU memory footprint."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:16.086570Z","iopub.status.busy":"2022-11-29T05:59:16.085536Z","iopub.status.idle":"2022-11-29T05:59:16.461173Z","shell.execute_reply":"2022-11-29T05:59:16.460092Z","shell.execute_reply.started":"2022-11-29T05:59:16.086521Z"},"trusted":true},"outputs":[],"source":["# LOAD XGB LIBRARY\n","from sklearn.model_selection import KFold\n","import xgboost as xgb\n","print('XGB Version',xgb.__version__)\n","\n","# XGB MODEL PARAMETERS\n","xgb_parms = { \n","    'max_depth':4, \n","    'learning_rate':0.05, \n","    'subsample':0.8,\n","    'colsample_bytree':0.6, \n","    'eval_metric':'auc',\n","    'objective':'binary:logistic',\n","    'tree_method':'gpu_hist',\n","    'predictor':'gpu_predictor',\n","    'random_state':SEED\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:16.463573Z","iopub.status.busy":"2022-11-29T05:59:16.463114Z","iopub.status.idle":"2022-11-29T05:59:16.473074Z","shell.execute_reply":"2022-11-29T05:59:16.471859Z","shell.execute_reply.started":"2022-11-29T05:59:16.463536Z"},"trusted":true},"outputs":[],"source":["# NEEDED WITH DeviceQuantileDMatrix BELOW\n","class IterLoadForDMatrix(xgb.core.DataIter):\n","    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n","        self.features = features\n","        self.target = target\n","        self.df = df\n","        self.it = 0 # set iterator to 0\n","        self.batch_size = batch_size\n","        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n","        super().__init__()\n","\n","    def reset(self):\n","        '''Reset the iterator'''\n","        self.it = 0\n","\n","    def next(self, input_data):\n","        '''Yield next batch of data.'''\n","        if self.it == self.batches:\n","            return 0 # Return 0 when there's no more batch.\n","        \n","        a = self.it * self.batch_size\n","        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n","        dt = cudf.DataFrame(self.df.iloc[a:b])\n","        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n","        self.it += 1\n","        return 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:16.982429Z","iopub.status.busy":"2022-11-29T05:59:16.981554Z","iopub.status.idle":"2022-11-29T05:59:16.993414Z","shell.execute_reply":"2022-11-29T05:59:16.991656Z","shell.execute_reply.started":"2022-11-29T05:59:16.982393Z"},"trusted":true},"outputs":[],"source":["# https://www.kaggle.com/kyakovlev\n","# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n","def amex_metric_mod(y_true, y_pred):\n","\n","    labels     = np.transpose(np.array([y_true, y_pred]))\n","    labels     = labels[labels[:, 1].argsort()[::-1]]\n","    weights    = np.where(labels[:,0]==0, 20, 1)\n","    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n","    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n","\n","    gini = [0,0]\n","    for i in [1,0]:\n","        labels         = np.transpose(np.array([y_true, y_pred]))\n","        labels         = labels[labels[:, i].argsort()[::-1]]\n","        weight         = np.where(labels[:,0]==0, 20, 1)\n","        weight_random  = np.cumsum(weight / np.sum(weight))\n","        total_pos      = np.sum(labels[:, 0] *  weight)\n","        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n","        lorentz        = cum_pos_found / total_pos\n","        gini[i]        = np.sum((lorentz - weight_random) * weight)\n","\n","    return 0.5 * (gini[1]/gini[0] + top_four)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["importances = []\n","oof = []\n","train = train.to_pandas() # free GPU memory\n","TRAIN_SUBSAMPLE = 1.0\n","gc.collect()\n","\n","skf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n","for fold,(train_idx, valid_idx) in enumerate(skf.split(\n","            train, train.target )):\n","    \n","    # TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\n","    if TRAIN_SUBSAMPLE<1.0:\n","        np.random.seed(SEED)\n","        train_idx = np.random.choice(train_idx, \n","                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n","        np.random.seed(None)\n","    \n","    print('#'*25)\n","    print('### Fold',fold+1)\n","    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n","    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n","    print('#'*25)\n","    \n","    # TRAIN, VALID, TEST FOR FOLD K\n","    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n","    X_valid = train.loc[valid_idx, FEATURES]\n","    y_valid = train.loc[valid_idx, 'target']\n","    \n","    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n","    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n","    \n","    # TRAIN MODEL FOLD K\n","    model = xgb.train(xgb_parms, \n","                dtrain=dtrain,\n","                evals=[(dtrain,'train'),(dvalid,'valid')],\n","                num_boost_round=9999,\n","                early_stopping_rounds=100,\n","                verbose_eval=100) \n","    model.save_model(f'XGB_v{VER}_fold{fold}.xgb')\n","    \n","    # GET FEATURE IMPORTANCE FOR FOLD K\n","    dd = model.get_score(importance_type='weight')\n","    df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n","    importances.append(df)\n","            \n","    # INFER OOF FOLD K\n","    oof_preds = model.predict(dvalid)\n","    acc = amex_metric_mod(y_valid.values, oof_preds)\n","    print('Kaggle Metric =',acc,'\\n')\n","    \n","    # SAVE OOF\n","    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n","    df['oof_pred'] = oof_preds\n","    oof.append( df )\n","    \n","    del dtrain, Xy_train, dd, df\n","    del X_valid, y_valid, dvalid, model\n","    _ = gc.collect()\n","    \n","print('#'*25)\n","oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n","acc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n","print('OVERALL CV Kaggle Metric =',acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# CLEAN RAM\n","del train\n","_ = gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Save OOF Preds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["oof_xgb = pd.read_parquet(TRAIN_PATH, columns=['customer_ID']).drop_duplicates()\n","oof_xgb['customer_ID_hash'] = oof_xgb['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n","oof_xgb = oof_xgb.set_index('customer_ID_hash')\n","oof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\n","oof_xgb = oof_xgb.sort_index().reset_index(drop=True)\n","oof_xgb.to_csv(f'oof_xgb_v{VER}.csv',index=False)\n","oof_xgb.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# PLOT OOF PREDICTIONS\n","plt.hist(oof_xgb.oof_pred.values, bins=100)\n","plt.hist(oof_xgb.target.values, bins=100, alpha=0.5)\n","plt.title('OOF Predictions')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# CLEAR VRAM, RAM FOR INFERENCE BELOW\n","del oof_xgb, oof\n","_ = gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Importance"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","df = importances[0].copy()\n","for k in range(1,FOLDS): df = df.merge(importances[k], on='feature', how='left')\n","df['importance'] = df.iloc[:,1:].mean(axis=1)\n","df = df.sort_values('importance',ascending=False)\n","df.to_csv(f'xgb_feature_importance_v{VER}.csv',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["NUM_FEATURES = 20\n","plt.figure(figsize=(10,5*NUM_FEATURES//10))\n","plt.barh(np.arange(NUM_FEATURES,0,-1), df.importance.values[:NUM_FEATURES])\n","plt.yticks(np.arange(NUM_FEATURES,0,-1), df.feature.values[:NUM_FEATURES])\n","plt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Process and Feature Engineer Test Data\n","We will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][1] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n","\n","[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n","[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n","[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n","[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n","[5]: https://rapids.ai/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T05:59:23.046506Z","iopub.status.busy":"2022-11-29T05:59:23.045828Z","iopub.status.idle":"2022-11-29T05:59:23.051648Z","shell.execute_reply":"2022-11-29T05:59:23.050672Z","shell.execute_reply.started":"2022-11-29T05:59:23.046469Z"},"trusted":true},"outputs":[],"source":["with open('/kaggle/working/FEATURES.json', 'r') as pf:\n","    FEATURES = json.load(pf)['FEATURES']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T06:07:39.207243Z","iopub.status.busy":"2022-11-29T06:07:39.206803Z","iopub.status.idle":"2022-11-29T06:07:40.273798Z","shell.execute_reply":"2022-11-29T06:07:40.272763Z","shell.execute_reply.started":"2022-11-29T06:07:39.207164Z"},"trusted":true},"outputs":[],"source":["# CALCULATE SIZE OF EACH SEPARATE TEST PART\n","def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n","    chunk = len(customers)//NUM_PARTS\n","    if verbose != '':\n","        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n","        print(f'There will be {chunk} customers in each part (except the last part).')\n","        print('Below are number of rows in each part:')\n","    rows = []\n","\n","    for k in range(NUM_PARTS):\n","        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n","        else: cc = customers[k*chunk:(k+1)*chunk]\n","        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n","        rows.append(s)\n","    if verbose != '': print( rows )\n","    return rows,chunk\n","\n","# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n","NUM_PARTS = 4\n","TEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'\n","\n","print(f'Reading test data...')\n","test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n","customers = test[['customer_ID']].drop_duplicates().values.flatten()\n","rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"]},{"cell_type":"markdown","metadata":{},"source":["# Infer Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T06:07:47.627959Z","iopub.status.busy":"2022-11-29T06:07:47.627570Z","iopub.status.idle":"2022-11-29T06:09:55.018390Z","shell.execute_reply":"2022-11-29T06:09:55.017202Z","shell.execute_reply.started":"2022-11-29T06:07:47.627923Z"},"trusted":true},"outputs":[],"source":["# INFER TEST DATA IN PARTS\n","skip_rows = 0\n","skip_cust = 0\n","test_preds = []\n","\n","for k in range(NUM_PARTS):\n","    \n","    # READ PART OF TEST DATA\n","    print(f'\\nReading test data...')\n","    test = read_file(path = TEST_PATH)\n","    test = test.iloc[skip_rows:skip_rows+rows[k]]\n","    skip_rows += rows[k]\n","    print(f'=> Test part {k+1} has shape', test.shape )\n","    \n","    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n","    test = process_and_feature_engineer(test)\n","    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n","    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n","    skip_cust += num_cust\n","    \n","    print('input test shape : ',test.shape)\n","    \n","    # TEST DATA FOR XGB\n","    X_test = test[FEATURES]\n","    dtest = xgb.DMatrix(data=X_test)\n","    test = test[['P_2_mean']] # reduce memory\n","    del X_test\n","    gc.collect()\n","\n","    # INFER XGB MODELS ON TEST DATA\n","    model = xgb.Booster()\n","    model.load_model(f'XGB_v{VER}_fold0.xgb')\n","    preds = model.predict(dtest)\n","    for f in range(1,FOLDS):\n","        model.load_model(f'XGB_v{VER}_fold{f}.xgb')\n","        preds += model.predict(dtest)\n","    preds /= FOLDS\n","    test_preds.append(preds)\n","\n","    # CLEAN MEMORY\n","    del dtest, model\n","    _ = gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Create Submission CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T06:11:36.497893Z","iopub.status.busy":"2022-11-29T06:11:36.497520Z","iopub.status.idle":"2022-11-29T06:11:36.794426Z","shell.execute_reply":"2022-11-29T06:11:36.793446Z","shell.execute_reply.started":"2022-11-29T06:11:36.497861Z"},"trusted":true},"outputs":[],"source":["# WRITE SUBMISSION FILE\n","test_preds = np.concatenate(test_preds)\n","test = cudf.DataFrame(index=customers,data={'prediction':test_preds})\n","sub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')[['customer_ID']]\n","sub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n","sub = sub.set_index('customer_ID_hash')\n","sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n","sub = sub.reset_index(drop=True)\n","\n","# DISPLAY PREDICTIONS\n","sub.to_csv(f'submission_xgb_v{VER}.csv',index=False)\n","print('Submission file shape is', sub.shape )\n","sub.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-29T06:12:41.058864Z","iopub.status.busy":"2022-11-29T06:12:41.058279Z","iopub.status.idle":"2022-11-29T06:12:41.250907Z","shell.execute_reply":"2022-11-29T06:12:41.249889Z","shell.execute_reply.started":"2022-11-29T06:12:41.058820Z"},"trusted":true},"outputs":[],"source":["sub.to_csv('/kaggle/working/submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# PLOT PREDICTIONS\n","plt.hist(sub.to_pandas().prediction, bins=100)\n","plt.title('Test Predictions')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
